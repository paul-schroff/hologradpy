{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n# Feedback algorithm example\n\nThis script calculates phase patterns for a phase-modulating liquid crystal on silicon (LCOS) spatial light modulator\n(SLM) to create accurate light potentials by modelling pixel crosstalk on the SLM and using conjugate gradient (CG)\nminimisation with camera feedback (see https://doi.org/10.1038/s41598-023-30296-6).\n\nUsing this script, it should be easy to switch between the different patterns from our publication, turn on pixel\ncrosstalk modelling and switch between the fast Fourier transform (FFT) and the angular spectrum method (ASM) to model\nthe propagation of light.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\nfrom hologradpy import patterns as p\nfrom hologradpy import error_metrics as m\nfrom hologradpy import calibrate_slm as clb\nfrom hologradpy import torch_functions as tfn\n\nfrom examples.experiment import Params, Camera, SlmDisp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we determine which computing hardware to use (CPU or GPU) and create instances from our custom hardware classes.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = tfn.check_device(verbose=True)   # Check for GPU\n\npms_obj = Params()\ncam_obj = Camera(np.array([960, 1280]), 3.75e-6, bayer=True)    # Create instance of camera class\nslm_disp_obj = SlmDisp(np.array([1024, 1280]), 12.5e-6)         # Create instance of SLM class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the camera feedback algorithm\nParameters for the phase-retrieval algorithm:\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npix = 1024                 # Number of pixels on SLM (npix * npix)\npropagation_type = 'fft'    # Propagation Type\noptimizer = 'cg'            # Optimizer\nloss_fn = 'amp'             # Loss function used during optimization\nfft_shift = True            # Perform FFT shift?\nprecision = 'single'        # Computational precision\npixel_crosstalk = False     # Model pixel crosstalk?\npix_res = 1                 # Subsampling factor of each SLM pixel\ndetect_vortices = False     # Detect vortices before the first camera feedback iteration?\nthreshold_vtx = 0.05        # Vortices are only detected in regions brighter than threshold (1 is maximum)\n\n# Path containing a previously calculated affine transform to calibrate the camera.\ntf_path = pms_obj.data_path + '23-08-29_18-42-53_torch_camcal/'\n\ncalc_transform = True           # Calculate new transform?\nmeasure_slm_intensity = False   # Measure the constant intensity at the SLM (laser beam profile)?\nmeasure_slm_phase = False       # Measure the constant phase at the SLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the initial SLM phase guess, the target light potential and the signal region:\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "guess_type = 'guess'                                            # Use analytical phase guess\nphase_angle = int(-npix // 4)                                   # Offset of the target light potential to the optical\n                                                                # axis in x- and y-direction in Fourier pixels to\n                                                                # calculate the gradient of linear phase.\nlinear_phase = np.array([phase_angle + 2, phase_angle - 2])   # Linear term of the initial phase guess\nquad_phase = np.array([4.7e-4, 0.5])                            # Quadratic term of the initial phase guess\n\n# Target Pattern\npattern = 'spot_array'                                          # Name of the target light potential\nmask_pos = int(phase_angle)                                     # Offset of the target light potential to the optical\n                                                                # axis in x- and y-direction in Fourier pixels\ntarget_width = int(npix // 2)                                   # Size of the target light potential\ntarget_blur = 2                                                 # Width of the blurring kernel for the target light\n                                                                # potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the camera feedback algorithm:\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cam_name = 'before'                     # Name of camera\nslm_disp_type = 'lut'                   # SLM display mode\niter_fb = 10                            # Number of camera feedback iterations\niter_cg = 50 * np.ones(iter_fb)         # Number of CG iterations per feedback iteration\nalpha = np.ones(iter_fb)                # Feedback gain parameter\nexp_time = 200                          # Exposure time of camera in microseconds\nn_frames_avg = 10                       # Number of camera pictures taken to average\nfeedback_blur = 0                       # Size of Gaussian blurring for camera feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the blurring kernel to model pixel crosstalk:\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if pixel_crosstalk is True:\n    extent = 3                          # Extent of crosstalk kernel in SLM pixels\n    q = 2.3                             # Crosstalk kernel order\n    sigma = 0.92 / slm_disp_obj.pitch   # Crosstalk kernel width\n    kernel_ct = p.pixel_ct_kernel(slm_disp_obj.pitch, pix_res, extent, q, sigma)\nelse:\n    kernel_ct = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs for the angular spectrum method:\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of pixels of zero-padded SLM plane\nif propagation_type == 'asm':\n    npix_pad = int(pms_obj.lens_aperture // pms_obj.slm_pitch)\nelse:\n    npix_pad = 2 * npix\n\nnpix_tot = npix_pad * pix_res                   # Total number of pixels (npix_tot * npix_tot)\nextent_lens = npix_pad * slm_disp_obj.pitch     # Spatial extent of computational lens plane [m]\npd1 = pms_obj.fl                                # Distance from SLM plane to lens plane [m]\npd2 = pms_obj.fl                                # Distance from lens plane to camera plane [m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which data to save.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save = False                    # Save camera images?\nconvergence = False             # Save convergence of CG algorithm?\nn_save = 5                      # Save every xx th CG iteration\niter_plot = [1, 2, 13, 14, 15]  # List of feedback iterations to save CG convergence\n\n# Create folder to save data\ndate_saved = time.strftime('%y-%m-%d_%H-%M-%S', time.localtime())\npath = pms_obj.data_path + date_saved + '_' + os.path.splitext(os.path.basename(__file__))[0] + '_' + pattern\nos.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the constant intensity and phase at the SLM\nMeasuring the constant intensity and phase at the SLM is crucial for accurate experimental results - see the\nsupplementary information of our publication for details.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if measure_slm_intensity is True:\n    i_path = clb.measure_slm_intensity(slm_disp_obj, cam_obj, pms_obj, 30, 32, 10000, 256, 300)\n    pms_obj.i_path = i_path\nif measure_slm_phase is True:\n    phi_path = clb.measure_slm_wavefront(slm_disp_obj, cam_obj, pms_obj, 30, 16, 64, 40000, 256, roi_min_x=2,\n                                         roi_min_y=2, roi_n=26)\n    pms_obj.phi_path = phi_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions above, this is our constant field at the SLM after upscaling it to the native resolution of the\nSLM:\n\n<img src=\"file://images/constant_slm_field.png\">\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the target light potential\nThe ``patterns.Hologram`` class contains pre-defined patterns from our publication. It creates\n\n- the upscaled measured constant SLM phase and intensity,\n- the initial SLM phase guess,\n- the target intensity pattern,\n- and the signal region.\n\nFeel free to define the arrays above yourself - using the ``patterns.Hologram`` class is not mandatory.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holo = p.Hologram(slm_disp_obj, pms_obj, pattern, npix, npix_pad=npix_pad, pix_res=pix_res, phase_guess_type=guess_type,\n                  linear_phase=linear_phase, quadratic_phase=quad_phase, slm_field_type='measured',\n                  propagation_type=propagation_type, target_position=mask_pos, target_width=target_width,\n                  target_blur=target_blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our target light potential, a Gaussian spot array, and the signal region:\n\n<img src=\"file://images/target.png\">\n\nThe target is shifted away from the center to avoid the zeroth order diffration spot. The phase retrieval algorithm\nonly optimises for the intensity inside the signal region.\n\nWe use an analytic initial SLM phase guess consisting of a quadratic and a linear phase term. The quadratic phase term\ndepends on the size and the aspect ratio of the target pattern while the linear term depends on the position of the\npattern with respect to the optical axis. The initial phase guess defined here looks like this:\n\n<img src=\"file://images/init_phase.png\" width=\"400\">\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a virtual SLM object\nThis is a digital twin of the experimental Fourier holography setup. The ``forward`` method of ``VirtualSlm`` takes an\nSLM phase pattern, models pixel crosstalk on the SLM and the propagation of light from the SLM to the camera. It\nreturns the electric field at the image plane.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create SLM mask to set unused pixels to zero\nslm_mask = np.zeros((npix, npix))\nslm_mask[pms_obj.crop:-pms_obj.crop, pms_obj.crop:-pms_obj.crop] = 1\n\n# Pixel pitch in the Fourier plane (padded) [m]\nimg_pitch = pms_obj.wavelength * pms_obj.fl / (slm_disp_obj.pitch * slm_disp_obj.res[0] * 2)\nxf = -256 * img_pitch  # ToDO: Explain this.\n\n# Create virtual SLM object\nslm_obj = tfn.VirtualSlm(slm_disp_obj, pms_obj, holo.phi_init, npix_pad, npix=npix, e_slm=holo.e_slm,\n                         kernel_ct=kernel_ct, pix_res=pix_res, propagation_type=propagation_type,\n                         extent_lens=pms_obj.lens_aperture, pd1=pd1, pd2=pd2, xf=xf, device=device, slm_mask=slm_mask,\n                         precision=precision, fft_shift=fft_shift).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration\nHere, we calculate the affine transformation matrix between camera coordinates and image plane coordinates. This is\nimportant to compare the simulated light potential to the captured camera image.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if calc_transform is False:\n    tf = np.load(tf_path + 'tf.npy')\n    itf = np.load(tf_path + 'itf.npy')\nelse:\n    # ToDO: Control over checkerboard position missing.\n    tf, itf = tfn.camera_calibration(slm_obj, slm_disp_obj, cam_obj, pms_obj, save=True, exp_time=1000,\n                                     checkerboard_rows=16, checkerboard_columns=12, checkerboard_square_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the result:\n\n<img src=\"file://images/cam_calib.png\">\n\nNote that the zeroth-order diffraction spot is now located in the center of the computational image plane on the right\nhand side.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the camera feedback algorithm\nFirst, we create an object from ``torch_functions.PhaseRetrieval`` which sets the phase retrieval method. By default,\n``torch_functions.PhaseRetrieval`` performs conjugate gradient minimisation using an amplitude-only cost function (see\nhttps://doi.org/10.1364/OE.22.026548).\n\nThis phase retrieval method is then used iteratively by the camera feedback algorithm\n(see https://dx.doi.org/10.1088/0953-4075/48/11/115303).\n\nBefore running the camera feedback algorithm, we set the phase of the virtual SLM , ``slm_obj``, with the initial\nphase guess. The phase pattern of ``slm_obj`` might have been modified by the ``torch_functions.camera_calibration``\nfunction.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phase_retrieval_obj = tfn.PhaseRetrieval(slm_obj, n_iter=int(iter_cg[0]), i_tar=holo.i_tar, signal_region=holo.sig_mask,\n                                         save=convergence, n_save=n_save)\n\nif propagation_type == 'asm':\n    # Modify the initial phase pattern on our virtual SLM if the ASM is used.\n    slm_obj.set_phi(holo.phi_init - slm_obj.asm_obj.phi_q_native)\nelse:\n    phase_retrieval_obj.slm_obj.set_phi(holo.phi_init)\n\n# Run camera feedback algorithm\noutput = tfn.camera_feedback(phase_retrieval_obj, slm_disp_obj, cam_obj, tf, itf, iter_fb=iter_fb, iter_cg=iter_cg,\n                             detect_vortices=detect_vortices, threshold_vtx=threshold_vtx, n_save=n_save,\n                             n_avg=n_frames_avg, exp_time=exp_time, fb_blur=feedback_blur, alpha=alpha,\n                             convergence=convergence, iter_convergence=iter_plot, path=path)\n\nphi, img, M, T, [rmse, psnr], [rmse_conv_sv, rmse_pred_conv_sv, eff_conv_sv, n_conv_sv] = output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first 50 CG iterations, the optimised SLM phase pattern is displayed on the device and a camera image is\ntaken:\n\n<img src=\"file://images/fb0.png\">\n\nThe experimental errors in the camera image are greatly reduced after 10 camera feedback iterations with 50 CG\niterations each:\n\n<img src=\"file://images/fb15.png\">\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transfer electric field in the image plane to CPU\ne_out = tfn.gpu_to_numpy(slm_obj())\n\n# Calculate intensity pattern of the simulated light potential\ni_out = np.abs(e_out) ** 2\n\n# Calculate phase pattern of simulated light potential\nphi_out = np.angle(e_out)\n\n# Calculate efficiency\neff = m.eff(holo.sig_mask, i_out)\nprint('Efficiency of the simulation:', eff * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "px = 1 / plt.rcParams['figure.dpi']\nfig0, axs0 = plt.subplots(figsize=(800*px, 400*px))\nplt.plot(np.arange(1, iter_fb + 1), rmse * 100, 'k*', label='RMS error')\nplt.title('Experimental RMS error vs iteration number')\nplt.xlabel('feedback iteration number')\nplt.ylabel('experimental RMS error [%]')\n\nplt.figure()\nplt.plot(psnr, 'go', label='PSNR')\nplt.title('Experimental PSNR vs iteration number')\nplt.xlabel('experimental iteration number')\nplt.ylabel('PSNR [dB]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the rms error of the camera images after each feedback iteration:\n\n<img src=\"file://images/rmse.png\">\n\nThe feedback algorithm lowered rms error from ~12 % to ~1.6 %.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\nplt.imshow(i_out, cmap='turbo')\nplt.title('Simulated light potential')\n\nplt.figure()\nplt.imshow(phi_out, cmap='magma')\nplt.title('Phase of simulated light potential')\n\nplt.figure()\nplt.imshow(img[..., -1].squeeze(), cmap='turbo')\nplt.title('Camera image')\nplt.savefig(path + '//img.pdf', dpi=1200)\n\ntarget_norm = T[..., 0].squeeze() * tfn.camera_feedback.sig_mask_tf\nmask_target = target_norm > 0.1 * np.max(target_norm)\ntarget_norm = target_norm / np.sum(target_norm[mask_target])\n\nimg_norm = img[..., 3].squeeze() * mask_target\nimg_norm = img_norm / np.sum(img_norm)\ndiff_img = (img_norm - target_norm) * mask_target\n\nplt.figure()\nplt.imshow(diff_img, cmap='seismic', vmin=-np.max(np.abs(diff_img)), vmax=np.max(np.abs(diff_img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can investigate the convergence of the phase retrieval algorithm in-between feedback iterations by saving\nintermediate phase patterns, displaying them on the SLM and capturing the resulting camera image. This allows us to\nsee when the rms error of the camera image converges to determine the number of CG iterations needed per feedback\niteration.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot and save convergence graphs\nif convergence is True:\n    plt.figure('rmse')\n    x = min(iter_plot)\n    for i in range(len(iter_plot)):\n        plt.figure('rmse')\n        x = np.linspace(iter_plot[i] - 1 + 1 / iter_cg[iter_plot[i] - 1],\n                        iter_plot[i] - 1 + n_conv_sv[i] * n_save / iter_cg[iter_plot[i] - 1], n_conv_sv[i])\n        line_exp, = plt.plot(x, rmse_conv_sv[i] * 100, '-', color='C0')\n        line_pred, = plt.plot(x, rmse_pred_conv_sv[i] * 100, '--', color='r')\n\n        plt.figure('eff')\n        plt.plot(x, eff_conv_sv[i] * 100, '-', color='C1')\n\n    line_exp.set_label('experiment')\n    line_pred.set_label('predicted')\n\n    plt.figure('rmse')\n    plt.plot(np.arange(1, iter_fb + 1), rmse * 100, 'k*', label='RMS within 50% of max. intensity')\n    plt.legend()\n    plt.xlabel('CG iterations')\n    plt.ylabel('RMS error [%]')\n    plt.grid()\n    plt.savefig(path + '//rmse.pdf', bbox_inches='tight', dpi=600)\n\n    plt.figure('eff')\n    plt.xlabel('CG iterations')\n    plt.ylabel('Predicted efficiency [%]')\n    plt.grid()\n    plt.savefig(path + '//efficiency.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data\nSaving data to the hard drive.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if save is True:\n    np.save(path + '//lin_phase', linear_phase)\n    np.save(path + '//quad_phase', quad_phase)\n    np.save(path + '//tf', tf)\n    np.save(path + '//itf', itf)\n    np.save(path + '//T', T)\n    np.save(path + '//npix', npix)\n    np.save(path + '//npix_pad', npix_pad)\n    np.save(path + '//pix_res', pix_res)\n    np.save(path + '//M', M)\n    np.save(path + '//img', img)\n    np.save(path + '//phi', phi)\n    np.save(path + '//prop', propagation_type)\n    np.save(path + '//exp_time', exp_time)\n    np.save(path + '//kernel_ct', kernel_ct)\n\n    np.save(path + '//rmse', rmse)\n    np.save(path + '//eff', eff)\n    np.save(path + '//psnr', psnr)\n\n    np.save(path + '//rmse_conv_sv', rmse_conv_sv)\n    np.save(path + '//rmse_pred_conv_sv', rmse_pred_conv_sv)\n    np.save(path + '//eff_conv_sv', eff_conv_sv)\n    np.save(path + '//n_conv_sv', n_conv_sv)\n    np.save(path + '//iter_plot', iter_plot)\n\n    np.save(path + '//a_tar', holo.a_tar)\n    np.save(path + '//sig_mask', holo.sig_mask)\n    np.save(path + '//n_save', n_save)\n    np.save(path + '//iter_fb', iter_fb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
