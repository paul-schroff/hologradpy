{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n# Setting up your hardware\n\nThis script sets constant experimental parameters and implements camera and SLM drivers. You will have to do this for\nyour own hardware.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\nimport numpy as np\nfrom hologradpy import hardware as hw\n\n# These modules are only needed for our camera and SLM drivers\nimport cv2 as cv\nfrom harvesters.core import Harvester\nfrom screeninfo import get_monitors\nimport imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting experimental parameters and other constant parameters\n\nTo start off, we write our own subclass of ``hardware.ParamsBase`` which sets some experimental parameters and other\nconstants needed in this script.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Params(hw.ParamsBase):\n    wavelength = 670e-9         # Wavelength [m]\n    beam_diameter = 7.25e-3     # Diameter of incident beam [m]\n    fl = 0.25                   # Focal length [m]\n\n    data_path = '../../holography_data/'\n\n    # Path to measured constant SLM phase and intenstiy\n    phi_path = data_path + '23-09-13_13-20-49_measure_slm_wavefront/dphi_uw.npy'\n    i_path = data_path + '23-09-13_11-47-42_measure_slm_intensity/i_rec.npy'\n\n    phi_filter_size = 2\n    crop = 64\n\n\npms_obj = Params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing SLM and camera drivers\nThis module provides the ``hardware.CameraBase`` class and the ``hardware.SlmDisp`` class to interface with the camera\nand the SLM. You will have to write your own subclasses for the specific devices you are using. Here, we defined the\nsubclasses ``Camera`` and ``SlmDisp`` to interface with a MatrixVision BlueFox 3 camera and a Hamamatsu SLM. Make sure\nyou implement all abstract methods of ``hw.CameraBase`` and ``hw.SlmBase`` in your own subclasses.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Camera(hw.CameraBase):\n    def __init__(self, res, pitch, name='before', roi=None, gain=0, bayer=False):\n        if roi is None:\n            roi = [1280, 960, 0, 0]\n        self.roi = roi\n        super().__init__(res, pitch, self.roi)\n        self.count = 0\n        self.gain = gain\n        self.bayer = bayer\n        self.name = name\n        self.h = None\n        self.ia = None\n        self.bayer_slope = 0.010487497932442524\n        self.bayer_offset = 2.195178550143578\n        self.max_frame_count = 2 ** 16 - 1\n\n    def start(self, n=1):\n        if n >= self.max_frame_count:\n            n = self.max_frame_count\n\n        self.h = Harvester()\n\n        self.h.add_file('C:/Program Files/MATRIX VISION/mvIMPACT Acquire/bin/x64/mvGenTLProducer.cti')\n\n        self.h.update()\n\n        print(\"start init ia\")\n\n        serial_numbers = []\n        for info in self.h.device_info_list:\n            serial_numbers.append(info.serial_number)\n        if self.name == 'before':\n            n_cam = serial_numbers.index('F0600075')\n        if self.name == 'after':\n            n_cam = serial_numbers.index('F0600086')\n        self.ia = self.h.create(n_cam)\n        self.ia.remote_device.node_map.ExposureAuto.value = 'Off'\n        self.ia.remote_device.node_map.mvLowLight.value = 'Off'\n        self.ia.remote_device.node_map.ExposureAuto.value = 'Off'\n        self.ia.remote_device.node_map.BlackLevelAuto.value = 'Off'\n        self.ia.remote_device.node_map.GainAuto.value = 'Off'\n        self.ia.remote_device.node_map.ExposureTime.value = 100\n        self.ia.remote_device.node_map.PixelFormat.value = 'Mono16'\n        self.ia.remote_device.node_map.AcquisitionMode.value = 'MultiFrame'\n        self.ia.remote_device.node_map.AcquisitionFrameRateEnable.value = True\n        self.ia.remote_device.node_map.AcquisitionFrameRate.value = 12\n        if self.name == 'before':\n            self.ia.remote_device.node_map.ReverseX.value = True\n            self.ia.remote_device.node_map.ReverseY.value = True\n        elif self.name == 'after':\n            self.ia.remote_device.node_map.ReverseX.value = False\n            self.ia.remote_device.node_map.ReverseY.value = True\n        self.ia.remote_device.node_map.TriggerMode.value = 'On'\n        self.ia.remote_device.node_map.TriggerSource.value = 'Software'\n        self.ia.remote_device.node_map.TriggerSelector.value = 'FrameStart'\n\n        w, h, dx, dy = self.roi\n\n        self.ia.remote_device.node_map.AcquisitionFrameCount.value = n\n        self.ia.remote_device.node_map.Gain.value = self.gain\n\n        if dx <= self.ia.remote_device.node_map.OffsetX.value:\n            self.ia.remote_device.node_map.OffsetX.value = dx\n            self.ia.remote_device.node_map.OffsetY.value = dy\n            self.ia.remote_device.node_map.Width.value = w\n            self.ia.remote_device.node_map.Height.value = h\n        else:\n            self.ia.remote_device.node_map.Width.value = w\n            self.ia.remote_device.node_map.Height.value = h\n            self.ia.remote_device.node_map.OffsetX.value = dx\n            self.ia.remote_device.node_map.OffsetY.value = dy\n\n        self.ia.start()\n        print(\"start acquisition\")\n\n    def get_image(self, exp_time_):\n        if self.count >= self.max_frame_count:\n            self.stop()\n            self.start(n=self.max_frame_count)\n\n        self.ia.remote_device.node_map.ExposureTime.value = exp_time_\n\n        self.ia.remote_device.node_map.TriggerSoftware.execute()\n\n        with self.ia.fetch() as buffer:\n            component = buffer.payload.components[0]\n            width = component.width\n            height = component.height\n\n            im = np.array(component.data.reshape(height, width)).astype(np.double)\n\n        if self.bayer is True:\n            im[0::2, 1::2] = im[0::2, 1::2] * (1 + self.bayer_slope) + self.bayer_offset\n            im[1::2, 0::2] = im[1::2, 0::2] * (1 + self.bayer_slope) + self.bayer_offset\n        self.count += 1\n        return im\n\n    def stop(self):\n        self.ia.stop()\n        print(\"stopped acquisition\")\n        self.ia.destroy()\n        self.h.reset()\n\n\nclass SlmDisp(hw.SlmBase):\n    def __init__(self, res, pitch, calib=None, delay=0.2, dx=0, dy=0):\n        super().__init__(res, pitch)\n        self.max_phase = 2 * np.pi  # Largest value for phase wrapping\n        self.slm_norm = 128         # Gray level on the SLM corresponding to max_phase\n        # Gray level vs phase lookup table\n        self.lut = np.load(pms_obj.data_path + '23-02-17_13-49-14_calibrate_grey_values/phase.npy')\n        self.idx_lut = np.argmin(np.abs(self.lut - self.max_phase))  # Index of max_phase in lut\n        self.lut = self.lut[:self.idx_lut]\n        # Path to Hamamatsu SLM correction pattern.\n        self.cal_path = pms_obj.data_path + 'deformation_correction_pattern/CAL_LSH0802439_' + '{:.0f}'.\\\n            format(np.around(pms_obj.wavelength * 1e9, decimals=-1)) + 'nm.bmp'\n        self.delay = 0.2  # Time to wait after displaying a phase pattern on the SLM [s]\n\n        if calib == 1 or calib is True:\n            self.calib_flag = True\n            self.calib = imageio.imread(self.cal_path)\n            self.calib = np.pad(self.calib, ((0, 0), (0, 8)))\n        elif calib == 0 or calib is False or calib is None:\n            self.calib_flag = False\n            self.calib = np.zeros((self.res[1], self.res[0]))\n        self.delay = delay\n        self.dx = dx\n        self.dy = dy\n\n        monitor = get_monitors()[-1]\n\n        cv.namedWindow('screen', cv.WINDOW_NORMAL)\n        cv.resizeWindow('screen', self.res[1], self.res[0])\n        cv.moveWindow('screen', monitor.x, monitor.y)\n        cv.setWindowProperty('screen', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)\n        cv.waitKey(100)\n        print(\"SlmDisp initialised\")\n\n    def display(self, phi_slm):\n        im_res_y, im_res_x = phi_slm.shape\n        slm_res_y, slm_res_x = self.res\n        slm_pad_x = (slm_res_x - im_res_x) // 2\n        slm_pad_y = (slm_res_y - im_res_y) // 2\n\n        slm_norm = self.slm_norm\n\n        if slm_pad_x == 0 and slm_pad_y == 0:\n            phi_zeros = slm_norm * phi_slm / (2 * np.pi)\n        elif -slm_pad_y - self.dy == 0:\n            phi_zeros = np.zeros((slm_res_y, slm_res_x))\n            phi_disp = slm_norm * phi_slm / (2 * np.pi)\n            phi_zeros[slm_pad_y - self.dy:, slm_pad_x - self.dx:-slm_pad_x - self.dx] = phi_disp\n        elif -slm_pad_x - self.dx == 0:\n            phi_zeros = np.zeros((slm_res_y, slm_res_x))\n            phi_disp = slm_norm * phi_slm / (2 * np.pi)\n            phi_zeros[slm_pad_y - self.dy:-slm_pad_y - self.dy, slm_pad_x - self.dx:] = phi_disp\n        else:\n            phi_zeros = np.zeros((slm_res_y, slm_res_x))\n            phi_disp = slm_norm * phi_slm / (2 * np.pi)\n            phi_zeros[slm_pad_y - self.dy:-slm_pad_y - self.dy, slm_pad_x - self.dx:-slm_pad_x - self.dx] = phi_disp\n\n        if self.calib_flag is False:\n            phi_zeros = phi_zeros.astype('uint8')\n        else:\n            phi_zeros = np.remainder(phi_zeros + self.calib, slm_norm).astype('uint8')\n\n        cv.imshow('screen', phi_zeros)\n        cv.waitKey(1)\n        time.sleep(self.delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the classes ``Params``, ``Camera`` and ``SlmDisp`` in other scripts.\n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
